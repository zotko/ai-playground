{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e574f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50367fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The grass is **green**.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM interface\n",
    "from langchain_google_genai.llms import GoogleGenerativeAI\n",
    "\n",
    "model = GoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "model.invoke(\"The grass is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93dda95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Germany is **Berlin**.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--325ee665-6eb6-45c1-84f3-7020c0286757-0', usage_metadata={'input_tokens': 7, 'output_tokens': 9, 'total_tokens': 16, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat interface\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "prompt = [HumanMessage(content=\"What is the capital of Germany?\")]\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30168408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**The capital of Germany is Berlin.**', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--883f5e90-a28f-433c-82f1-34dba46dfe9b-0', usage_metadata={'input_tokens': 20, 'output_tokens': 9, 'total_tokens': 29, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Roles: HumanMessage, AIMessage, SystemMessage, ChatMessage\n",
    "system_msg = SystemMessage(\n",
    "    \"You are a helpful assistant who responds to questions using bold text.\"\n",
    ")\n",
    "human_msg = HumanMessage(\"What is the capital of Germany?\")\n",
    "prompt = [system_msg, human_msg]\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74e370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Summarize the following text in 1 sentence. \\nIf the text is too short or lacks meaningful content, respond with \"Not enough information to summarize.\"\\n\\nText: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications.\\n    As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\nSummary: ')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Templates make prompts reusable\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    \"\"\"Summarize the following text in 1 sentence. \n",
    "If the text is too short or lacks meaningful content, respond with \"Not enough information to summarize.\"\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Summary: \"\"\"\n",
    ")\n",
    "\n",
    "# Example input\n",
    "template.invoke(\n",
    "    {\n",
    "        \"text\": \"\"\"LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications.\n",
    "    As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\"\"\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fbd218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Use the following context to answer \\n    the question. If the answer is not available in the context, respond with \\n    \"Not enough information provided\".\\n\\nContext: Video games come in many genres. Action games focus on fast \\n        movement and quick reflexes. Puzzle games require players to think and \\n        solve problems. Role-playing games, or RPGs, let players explore worlds \\n        and complete quests as different characters.\\n\\nQuestion: What type of games involve solving problems?\\n\\nAnswer: ')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = PromptTemplate.from_template(\n",
    "    \"\"\"Use the following context to answer \n",
    "    the question. If the answer is not available in the context, respond with \n",
    "    \"Not enough information provided\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "prompt = template.invoke(\n",
    "    {\n",
    "        \"context\": \"\"\"Video games come in many genres. Action games focus on fast \n",
    "        movement and quick reflexes. Puzzle games require players to think and \n",
    "        solve problems. Role-playing games, or RPGs, let players explore worlds \n",
    "        and complete quests as different characters.\"\"\",\n",
    "        \"question\": \"What type of games involve solving problems?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83355f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Puzzle games', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--c409d084-34c2-4785-963f-52a21c0da85e-0', usage_metadata={'input_tokens': 107, 'output_tokens': 3, 'total_tokens': 110, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23787f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Answer the question based on the context below. If the \\n        question cannot be answered using the information provided, answer with \\n        \"I don\\'t know\".', additional_kwargs={}, response_metadata={}), HumanMessage(content='Context: Modern gaming has evolved rapidly with the introduction of powerful graphics engines and online multiplayer capabilities. Popular platforms include PC, PlayStation, Xbox, and Nintendo Switch. Gamers often use services like Steam, PlayStation Network, and Xbox Live to access a vast library of titles and connect with friends around the world.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Question: Which platforms are popular for gaming?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Answer the question based on the context below. If the \n",
    "        question cannot be answered using the information provided, answer with \n",
    "        \"I don\\'t know\".\"\"\",\n",
    "        ),\n",
    "        (\"human\", \"Context: {context}\"),\n",
    "        (\"human\", \"Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = template.invoke(\n",
    "    {\n",
    "        \"context\": \"\"\"Modern gaming has evolved rapidly with the introduction of powerful graphics engines and online multiplayer capabilities. Popular platforms include PC, PlayStation, Xbox, and Nintendo Switch. Gamers often use services like Steam, PlayStation Network, and Xbox Live to access a vast library of titles and connect with friends around the world.\"\"\",\n",
    "        \"question\": \"Which platforms are popular for gaming?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730810e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='PC, PlayStation, Xbox, and Nintendo Switch.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--d710cfe1-a407-4b54-9ea5-ed9ced842a59-0', usage_metadata={'input_tokens': 104, 'output_tokens': 11, 'total_tokens': 115, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05000ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GamingAnswerWithJustification(answer='This information is not available.', justification='I do not have access to data regarding the popularity of PC versus console for online multiplayer gaming.')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JSON Output\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class GamingAnswerWithJustification(BaseModel):\n",
    "    \"\"\"An answer to the user's gaming question along with justification for the\n",
    "    answer.\"\"\"\n",
    "\n",
    "    answer: str\n",
    "    \"\"\"The answer to the user's gaming question\"\"\"\n",
    "    justification: str\n",
    "    \"\"\"Justification for the answer\"\"\"\n",
    "\n",
    "\n",
    "structured_llm = model.with_structured_output(GamingAnswerWithJustification)\n",
    "\n",
    "result = structured_llm.invoke(\n",
    "    \"\"\"Which platform is more popular for online multiplayer gaming, PC or console?\"\"\"\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ed82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"answer\":\"This information is not available.\",\"justification\":\"I do not have access to data regarding the popularity of PC versus console for online multiplayer gaming.\"}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b10717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'banana', 'cherry']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output parsing\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "parser.invoke(\"apple, banana, cherry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b17f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--43a2f765-b3d6-428b-8571-d4e6421864d2-0', usage_metadata={'input_tokens': 2, 'output_tokens': 11, 'total_tokens': 13, 'input_token_details': {'cache_read': 0}}),\n",
       " AIMessage(content='Hallo! Wie kann ich dir heute helfen?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--9b68184f-5c86-413e-8ce6-6a5ffcd4abff-0', usage_metadata={'input_tokens': 2, 'output_tokens': 10, 'total_tokens': 12, 'input_token_details': {'cache_read': 0}}),\n",
       " AIMessage(content=\"Bonjour ! Comment puis-je vous aider aujourd'hui ?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--112fc155-14fd-4449-acae-69e89876a669-0', usage_metadata={'input_tokens': 2, 'output_tokens': 13, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}}),\n",
       " AIMessage(content='Привіт! Чим можу допомогти? 😊', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--9c2789d1-4d9b-477f-bf1d-f9f871e5fa99-0', usage_metadata={'input_tokens': 3, 'output_tokens': 11, 'total_tokens': 14, 'input_token_details': {'cache_read': 0}})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch processing\n",
    "model.batch([\"Hi!\", \"Hallo!\", \"Bonjour!\", \"Привіт!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='I' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--b73fd203-a346-4ca5-b2a6-ff9b258a0572' usage_metadata={'input_tokens': 5, 'output_tokens': 0, 'total_tokens': 5, 'input_token_details': {'cache_read': 0}}\n",
      "content=' am doing well' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--b73fd203-a346-4ca5-b2a6-ff9b258a0572' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
      "content=\", thank you for asking! As a large language model, I don't\" additional_kwargs={} response_metadata={'safety_ratings': []} id='run--b73fd203-a346-4ca5-b2a6-ff9b258a0572' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
      "content=' experience emotions or physical sensations in the same way humans do, but I am functioning' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--b73fd203-a346-4ca5-b2a6-ff9b258a0572' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
      "content=' as intended and ready to assist you. How can I help you today?\\n' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--b73fd203-a346-4ca5-b2a6-ff9b258a0572' usage_metadata={'input_tokens': -1, 'output_tokens': 52, 'total_tokens': 51, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Streaming processing\n",
    "for token in model.stream(\"How are you?\"):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd5b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--1f690184-5871-4c3d-aacb-72aa6542992e-0', usage_metadata={'input_tokens': 13, 'output_tokens': 8, 'total_tokens': 21, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imperative composition\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    return model.invoke(prompt)\n",
    "\n",
    "\n",
    "chatbot.invoke({\"question\": \"What is the capital of France?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f64d650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--f7d91889-8d17-4526-b424-1b33f92299c4' usage_metadata={'input_tokens': 14, 'output_tokens': 0, 'total_tokens': 14, 'input_token_details': {'cache_read': 0}}\n",
      "content=' capital of Greece' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--f7d91889-8d17-4526-b424-1b33f92299c4' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
      "content=' is Athens.\\n' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--f7d91889-8d17-4526-b424-1b33f92299c4' usage_metadata={'input_tokens': -1, 'output_tokens': 8, 'total_tokens': 7, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Streaming\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    for token in model.stream(prompt):\n",
    "        yield token\n",
    "\n",
    "\n",
    "for part in chatbot.stream({\"question\": \"What is the capital of Greece?\"}):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf861a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='South Africa does not have one capital city, but three! They are:\\n\\n*   **Pretoria** (executive capital)\\n*   **Cape Town** (legislative capital)\\n*   **Bloemfontein** (judicial capital)', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--a508e2b2-4e7a-4d00-90f8-71d280321ba9-0', usage_metadata={'input_tokens': 14, 'output_tokens': 50, 'total_tokens': 64, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Asynchronous processing\n",
    "@chain\n",
    "async def chatbot(values):\n",
    "    prompt = await template.ainvoke(values)\n",
    "    return await model.ainvoke(prompt)\n",
    "\n",
    "\n",
    "await chatbot.ainvoke({\"question\": \"What is the capital of South Africa?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ffdead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Italy is Rome.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--8c147277-5bd4-42ca-b95f-b18a5189319a-0', usage_metadata={'input_tokens': 13, 'output_tokens': 8, 'total_tokens': 21, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declarative composition\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chatbot = template | model\n",
    "chatbot.invoke({\"question\": \"What is the capital of Italy?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55635b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--f9acd358-2bc0-4af2-850e-4d442eead70b' usage_metadata={'input_tokens': 14, 'output_tokens': 0, 'total_tokens': 14, 'input_token_details': {'cache_read': 0}}\n",
      "content=' capital of Spain is Madrid.\\n' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--f9acd358-2bc0-4af2-850e-4d442eead70b' usage_metadata={'input_tokens': -1, 'output_tokens': 8, 'total_tokens': 7, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "for part in chatbot.stream({\"question\": \"What is the capital of Spain?\"}):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b16a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
